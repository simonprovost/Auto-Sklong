{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"contribution/","title":"\ud83e\udd1d Contributing to Auto-Sklong","text":""},{"location":"contribution/#contributing-to-auto-sklong_1","title":"\ud83e\udd1d Contributing to Auto-Sklong","text":"<p>Given the extensive contributing guidelines for <code>Sklong</code>, you could follow the same here. Next, given this current project is a fork of <code>GAMA</code>, you could also follow their contribution's page here.</p>"},{"location":"experiments/","title":"\ud83d\udd2c Experimentation for <code>Auto-Sklong</code> (for the paper's reproduction)","text":""},{"location":"experiments/#experimentation-for-auto-sklong-for-the-papers-reproduction_1","title":"\ud83d\udd2c Experimentation for <code>Auto-Sklong</code> (for the paper's reproduction)","text":"<p>Be aware we have reworked the experiments engine</p> <p>During the research for the <code>Auto-Sklong</code> paper, we used a different engine  for the experiments. This engine was more hard-coded, with some tweaks  that were not publishable. Therefore, we reworked the engine to be more user-friendly  and to provide a better experience for the user, as well as for further experimenting  with <code>Auto-Sklong</code>, especially against other AutoML libraries or baseline algorithms/neural  networks \u2013 for us too!</p> <p>A better engine: <code>AutoML Benchmark</code></p> <p>@PGijsbers' et al. have created a flexible  experimentation-based system for AutoML libraries called <code>AutoML Benchmark</code>.  This system is much more flexible and user-friendly than the engine we provide with  <code>Auto-Sklong</code>. However, at the time, we did not have both access and time to explore  this benchmark system. In the future, we may, but in the meantime, what we deliver below  is for the paper's reproduction. In other words, use the  <code>AMLB: an AutoML Benchmark</code> for a better experience  with your AutoML experiments against others, including <code>Auto-Sklong</code>.</p>"},{"location":"experiments/#experiments","title":"\ud83d\udcda Experiments","text":"<p>The paper is submitted to a conference</p> <p>The paper is submitted to a conference, and we are awaiting the reviews.  This means that users cannot yet read the paper, but we will provide the link as  soon as it is accepted. Stay tuned!</p> <p>The documentation below is intended to help users understand how we achieved the results presented in our paper.  Nonetheless, we urge readers to read all the above information and warning blocks before proceeding.</p>"},{"location":"experiments/#introduction","title":"\ud83d\udcfd\ufe0f Introduction","text":"<p>First and foremost, we provide an engine that is flexible, but not as flexible as the  <code>AutoML Benchmark</code> system mentioned above. Our engine allows for a comparison of any system  to <code>Auto-Sklong</code>. The engine utilises a Nested Cross-Validation (NCV) approach to evaluate systems and algorithms (as per our paper).</p> <p>We provide the engine with the required number of folds to assess the system/algorithm,  which automatically partitions the original data if necessary, in order to then acquire the train  and test sets and run only on the required fold number (i.e, you have to run this for each outer fold of your NCV).</p> <p>The engine therefore uses the reporter method to report metrics that can be compared to other  systems or algorithms afterwards. The following sections will cover how to use the engine  for an existing system or algorithm, as well as how to add a new system or algorithm.</p>"},{"location":"experiments/#how-to-access-the-experiments-engine","title":"\ud83c\udf0d How to access the experiments engine","text":"<p>We have provided all the experiments-based information in a single branch  called <code>experiments</code>. Therefore, if you would like to explore the code's engine and how we  conducted the experiments, please visit the <code>experiments</code> branch.</p> <p>To do this, you can clone the repository and check out the <code>experiments</code> branch:</p> <pre><code>git clone &lt;repository-url&gt;\ncd &lt;repository-name&gt;\ngit checkout experiments\n</code></pre>"},{"location":"experiments/#how-to-use-the-experiments-engine","title":"\u2705 How to use the experiments engine","text":"<p>Navigate through the experiments folder and you should find  <code>experiments_engine.py</code> and another folder <code>experiments_launchers</code>.</p> <p>The engine allows for any launchers, such as those to run experiments on  <code>Auto-Sklong</code>, <code>Auto-Sklearn</code>, or any other systems, to be executed with a shared reporting method to compare them all together afterwards. This is because the engine generates CSV results for each NCV's outer-fold results, therefore, the shared reporting manners are needed to have a similar CSV format for all systems or algorithms.</p>"},{"location":"experiments/#1-use-an-available-launcher","title":"1\ufe0f\u20e3 Use an available launcher","text":"<p>At present, launchers for <code>Auto-Sklong</code>, <code>Auto-Sklearn</code>, <code>Random Forest</code>, and <code>Lexico Random Forest</code>  as per the paper's experiments are available. This means that you can use these launchers to run  the experiments.</p> <p>To do this, you may create bash scripts that will set up the available parameters,  refer to those launchers accordingly to understand what is available, and then conclude the  bash script with a Python run of the launcher of interest. For example, you can refer to the  folder <code>24_hours</code>, which contains the bash scripts used to run the experiments for 24 hours  in the paper.</p> <p>All launchers have default hyperparameters for their respective systems or algorithms used in the paper, but you can change them by providing different values in the bash script at your convenience.</p>"},{"location":"experiments/#2-add-a-new-launcher","title":"2\ufe0f\u20e3 Add a new launcher","text":"<p>Duplicate an existing launcher</p> <p>If you would like to add a new launcher, we recommend doing so by duplicating an existing  launcher and modifying it according to your needs.</p> <p>To add a new launcher, you can create a new Python file in the <code>experiments_launchers</code> folder.  The new launcher should have the following available methods:</p> <ul> <li>A reporter function that could follow the convention <code>def _reporter_&lt;your_system_name&gt;(system: &lt;your_system_type&gt;, X_test: pd.DataFrame) -&gt; dict[str, Any]:</code>.</li> </ul> <p>In a nutshell, this reporter function acquires the fitted system and the test set, and then  returns a dictionary of metrics that you would like to report. The expected outputs should look like this:</p> <pre><code>dict[str, Any]: A dictionary containing the following keys:\n    - \"predictions\": Predictions made by the system.\n    - \"probability_predictions\": Probability predictions made by the system.\n    - \"best_pipeline\": A dictionary with the names of the techniques used in the best pipeline for data preparation, preprocessing, and classification.\n    - \"metric_optimised\": The name of the metric that was optimized during training.\n</code></pre> <p>Sometimes you may not be able to fill out some of the above needed information</p> <p>For exemple in <code>best_pipeline</code>, sometimes baselines algorithms such as <code>random forest</code> do not create a <code>best_pipeline</code> as it is not a pipeline-based algorithm. Therefore, you can create the dictionary with the keys  but values set to the information you would like to report. For example, for <code>best_pipeline</code> you can set the value to  <code>\"Random Forest\"</code> to <code>classification</code>. See the <code>Random Forest</code> launcher for an example.</p> <ul> <li> <p>A launcher class that contains the following methods:</p> <ul> <li><code>__init__</code>: to acquire the arguments provided by the bash script.</li> <li><code>validate_parameters</code>: to validate the parameters provided by the bash script.</li> <li><code>launch_experiment</code>: to use the generic engine, and provide (1) your data and the Nested Cross-Validation parameters, (2) your custom system and its hyperparameters, and your reporter method previously created.</li> <li><code>default_parameters</code>: to provide the default parameters for your system or algorithm, which are not provided by the bash scripts.</li> </ul> </li> <li> <p>A main method that will be used to run the launcher. This method should start by acquiring the necessary arguments  from the bash scripts, in order to then execute the Launcher class, validate the parameters, and launch the experiment.</p> </li> </ul> <p>Be aware that path modifications are needed</p> <p>To use the current bash scripts available in the <code>24_hours</code> folder, you will need to modify the paths in a few lines.  We recommend you open one bash script to see how the paths are set up, and then modify them accordingly.  These bash scripts are made to run in a SLURM architecture, but you can modify them to run on your local machine or any other architecture (cloud-based, etc.).</p> <p>Data availability</p> <p>The data used in the paper is not available in the repository. This does not mean that it is not available at all.  Contact us if you would like to have access to the data used in the paper. You will need to pass some checks per  the data source: https://www.elsa-project.ac.uk/</p> <p>Therefore, this also means that all paths to data in the bash scripts will need to be modified to your own path where the data is stored on your machine/cluster.</p> <p>For further information</p> <p>If you would like to have further information on how to use the engine, or how to add a new launcher, please walk through the experiments folder's python files. They are docstring-based documented.</p>"},{"location":"experiments/#how-to-gather-all-results-from-each-ncvs-outer-fold","title":"\u2705 How to gather all results from each NCV's outer-fold","text":"<p>After running the experiments, you will have a CSV file for each NCV's outer-fold. To gather all the results you can use the last python file, called <code>experiments_gather_results.py</code>. Fill out the main's <code>root_folders</code> list variable with the root folders to each experiments done (parent of each NCV's outer-fold CSV files). Then run the script.</p> <p>It will navigate through each NCv's outer-fold CSV files, gather the results, and create a CSV file with all the results Sorting by default by the <code>Fold</code> column numbers.</p>"},{"location":"faq/","title":"\ud83d\udc40 Frequently Asked Questions","text":""},{"location":"faq/#frequently-asked-questions_1","title":"\ud83d\udc40 Frequently Asked Questions","text":"<p>Here are some common questions about <code>Auto-Sklong</code> and their answers.</p> <p>What is Longitudinal Data?</p> <p>Longitudinal Data refers to observations made on multiple variables of interest for the same subject  over an extended period of time. This type of data is particularly valuable for studying  changes and trends, as well as making predictions about future outcomes. For example, in  a medical study, a patient's health measurements such as blood pressure, heart rate,  and weight might be recorded over several years to analyze the effectiveness of a treatment.</p> <p>What are the differences between Time-Series Data and Longitudinal Data?</p> <p>Time-Series Data and Longitudinal Data both involve observations made over time, but they differ in several aspects:</p> <ul> <li>Focus: Originally Time-Series Data focuses on a single variable measured at regular intervals, while Longitudinal Data involves multiple variables observed over time for each subject.</li> <li>Nature: Time-Series Data is usually employed for continuous data, whereas Longitudinal Data can handle both continuous and categorical data.</li> <li>Time gap: Time-Series Data typically deals with shorter time periods (e.g., seconds, minutes, or hours), while Longitudinal Data often spans longer durations (e.g., months or years).</li> <li>Irregularity: Time-Series Data is often regularly spaced, while Longitudinal Data can have irregular time intervals between observations.</li> <li>Machine Learning: Time-Series Data are frequently used to predict future values, whereas Longitudinal Data are more frequently used to predict future outcomes. In addition,  the ML algorithms used for time-series are frequently distinct from those used for longitudinal data. For instance, Time-Series based techniques are based on time-windowing techniques, whereas Longitudinal based techniques frequently  use the current standard for machine learning classification for the prediction task.  Nevertheless, they will adapt (create variant of these standard classification based machine learning algorithm)  to comprehend the temporal nature of the data.</li> </ul> <p>In summary, the main differences between Time-Series and Longitudinal Data lie in the focus, nature, and the length of the time intervals considered.</p> <p>Are there any limitations I should be aware of?</p> <ol> <li> <p>It's important to be aware that, as of today's date, <code>Auto-Sklong</code> does not support regression tasks nor  Neural-Networks adapted for Longitudinal Data.  However, we are constantly working to improve the library and add new features, so be sure to check for updates  regularly or contribute to the project on GitHub.</p> </li> <li> <p>The library is still in its early stages, with a new novel <code>search space</code>, yet the search methods are all existing search methods. Stay tuned for more updates!</p> </li> </ol> <p>Where can I find more resources?</p> <p>If you're looking for more information on how to use <code>Auto-Sklong</code>, check out our API Reference and Examples pages.</p> <p>What if I have a question that isn't answered here?</p> <p>If you have a question that isn't answered here, feel free to reach out to us on  GitHub Issues.</p>"},{"location":"faq/#related-projects","title":"Related Projects","text":"<p>Sklong</p> <ul> <li>Open-source: \u2705</li> <li>Authors: Simon Provost &amp; Alex Freitas</li> <li>Github Link: Sklong</li> <li>Description: Scikit-Longitudinal (Sklong) is a machine learning library tailored to cope with       longitudinal data in Longitudinal ML classification context. It is built on top of scikit-learn and provides       tools to preprocess, model, and evaluate longitudinal data. Nothing is AutoML related in this project.       Auto-Sklong is there for that purpose.  </li> </ul> <p>Auto-prognosis</p> <ul> <li>Open-source: \u2705</li> <li>Authors: VanderSchaar Lab</li> <li>Github Link: Auto-prognosis</li> <li>Description: AutoPrognosis - A system for automating the design of predictive modeling pipelines tailored for clinical prognosis.</li> <li>Note: Auto-prognosis is highly correlated with the StepWise Model Selection Via Deep Kernel Learning (SMS-DKL) and the Clairvoyance projects. Worth reading the paper, yet the project despite being open source is very limited.</li> </ul> <p>Clairvoyance</p> <ul> <li>Open-source: \u2705</li> <li>Authors: VanderSchaar Lab</li> <li>Github Link: Clairvoyance</li> <li>Description: Clairvoyance - A Pipeline Toolkit for Medical Time Series</li> </ul> <p>LongiTools</p> <ul> <li>Open-source: \u23f3</li> <li>Authors: LongiTools</li> <li>Official Website: LongiTools</li> <li>Description: A European research project studying the interactions between environmental, lifestyle and biological factors to determine the risks of chronic cardiovascular and metabolic diseases.</li> </ul>"},{"location":"quick-start/","title":"\ud83d\udca1 About The Project","text":""},{"location":"quick-start/#about-the-project_1","title":"\ud83d\udca1 About The Project","text":"<p>Longitudinal datasets contain information about the same cohort of individuals (instances) over time,  with the same set of features (variables) repeatedly measured across different time points  (also called <code>waves</code>) [1,2].</p> <p><code>Scikit-Longitudinal</code>, also called <code>Sklong</code>is a machine learning library designed to analyse longitudinal data, also called Panel data in certain fields. Today, <code>Sklong</code>  is focussed on the Longitudinal Machine Learning Classification task. It offers tools and models for processing, analysing,  and classify longitudinal data, with a user-friendly interface that  integrates with the <code>Scikit-learn</code> ecosystem.</p> <p><code>Auto-Scikit-Longitudinal</code> (Auto-Sklong) is an Automated Machine Learning (AutoML) library, developed upon the <code>General Machine Learning Assistant (GAMA)</code> framework,  introduces a brand-new <code>search space</code> leveraging both <code>Sklong</code> and <code>Scikit-learn</code>  models to tackle the Longitudinal machine learning classification tasks.</p> <p><code>Auto-Sklong</code> comes with various search method to explore the <code>search space</code> introduced. <code>Bayesian Optimisation</code></p>"},{"location":"quick-start/#installation","title":"\ud83d\udee0\ufe0f Installation","text":"<p>To install <code>Auto-Sklong</code>, take these two easy steps:</p> <ol> <li>\u2705 Install the latest version of <code>Auto-Sklong</code>:</li> </ol> <p><pre><code>pip install Auto-Sklong\n</code></pre> You could also install different versions of the library by specifying the version number,  e.g. <code>pip install Auto-Sklong==0.0.1</code>.  Refer to Release Notes</p> <ol> <li>\ud83d\udce6 [MANDATORY] Update the required dependencies (Why? See here)</li> </ol> <p><code>Auto-Sklong</code> incorporates via <code>Sklong</code> a modified version of <code>Scikit-Learn</code> called <code>Scikit-Lexicographical-Trees</code>,  which can be found at this Pypi link.</p> <p>This revised version guarantees compatibility with the unique features of <code>Scikit-longitudinal</code>.  Nevertheless, conflicts may occur with other dependencies in <code>Auto-Sklong</code> that also require <code>Scikit-Learn</code>.  Follow these steps to prevent any issues when running your project.</p> \ud83e\udef5 Simple Setup: Command Line Installation  Say you want to try `Auto-Sklong` in a very simple environment. Such as without a proper `project.toml` file (`Poetry`, `PDM`, etc). Run the following command:  <pre><code>pip uninstall scikit-learn scikit-lexicographical-trees &amp;&amp; pip install scikit-lexicographical-trees\n</code></pre> \ud83e\udef5 Project Setup: Using `UV`  Imagine you are managing your project with **UV**, a powerful and flexible project management tool. Below is an example configuration for integrating **UV** in your `pyproject.toml` file.  To ensure smooth operation and avoid dependency conflicts, you can override specific dependencies like `Scikit-Learn`. Add the following configuration to your `pyproject.toml`:  <pre><code>[tool.uv]\npackage = true\noverride-dependencies = [\n    \"scikit-learn ; sys_platform == 'never'\",\n]\n</code></pre>  This setup ensures that UV will manage your project\u2019s dependencies efficiently, while avoiding conflicts with Scikit-Learn.   \ud83e\udef5 Project Setup: Using `PDM`  Imagine you have a project being managed by `PDM`, or any other package manager. The example below demonstrates `PDM`.  Nevertheless, the process is similar for `Poetry`.  Therefore, to prevent dependency conflicts, you can exclude `Scikit-Learn` by adding the provided configuration  to your `pyproject.toml` file.  <pre><code>[tool.pdm.resolution]\nexcludes = [\"scikit-learn\"]\n</code></pre>  *This exclusion ensures Scikit-Lexicographical-Trees (used as `Scikit-learn`) is used seamlessly within your project.*"},{"location":"quick-start/#installing-auto-sklong-on-apple-silicon-macs","title":"\ud83d\udc3e Installing <code>Auto-Sklong</code> on Apple Silicon Macs","text":"<p>Apple Silicon-based Macs require running under an <code>x86_64</code> architecture to ensure proper installation and functioning  of <code>Auto-Sklong</code>. Below is a step-by-step guide using UV as the state-of-the-art package manager to address this:</p> <p>Note that this is mainly due to Deep-Forest not being compatible with Apple Silicon.</p>"},{"location":"quick-start/#step-1-start-a-terminal-session-under-x86_64-architecture","title":"Step 1: Start a Terminal Session Under <code>x86_64</code> Architecture","text":"<p>Run the following command to instantiate a <code>zsh</code> shell under the <code>x86_64</code> architecture:</p> <p><pre><code>arch -x86_64 zsh\n</code></pre> Further reading: Switching Terminal Between x86_64 and ARM64.</p>"},{"location":"quick-start/#step-2-install-an-x86_64-python-version","title":"Step 2: Install an <code>x86_64</code> Python Version","text":"<p>Install an <code>x86_64</code> compatible Python version using UV:</p> <p><pre><code>uv python install cpython-3.9.21-macos-x86_64-none # Can be using another 3.9.x version. Run `uv python list` to see available versions.\n</code></pre> Reference: UV Python Install Documentation.</p>"},{"location":"quick-start/#step-3-set-up-an-isolated-environment","title":"Step 3: Set Up an Isolated Environment","text":"<p>To avoid conflicts, set up a virtual environment:</p> <pre><code>uv venv\nsource .venv/bin/activate\n</code></pre>"},{"location":"quick-start/#step-4-pin-the-installed-python-version","title":"Step 4: Pin the Installed Python Version","text":"<p>Ensure that the installed <code>x86_64</code> Python version is the one used by UV:</p> <p><pre><code>uv python pin cpython-3.9.21-macos-x86_64-none\n</code></pre> Reference: UV Python Pin Documentation.</p>"},{"location":"quick-start/#step-5-install-auto-sklong","title":"Step 5: Install <code>Auto-Sklong</code>","text":"<p>Finally, install <code>Auto-Sklong</code> under the correct architecture:</p> <pre><code>uv pip install auto-sklong\n# Alternatively\nuv add auto-sklong\n</code></pre>"},{"location":"quick-start/#post-installation","title":"Post-Installation","text":"<p>Once installed, follow the UV documentation or use Python as usual.</p> <p>If you prefer a package manager other than UV, you can use it as long as you're operating under the <code>x86_64</code> architecture.</p>"},{"location":"quick-start/#developer-notes","title":"\ud83d\udcbb Developer Notes","text":"<p>For developers looking to contribute, please refer to the <code>Contributing</code> section of <code>GAMA</code> here and <code>Scikit-Longitudinal</code> here.</p>"},{"location":"quick-start/#supported-operating-systems","title":"\ud83d\udee0\ufe0f Supported Operating Systems","text":"<p><code>Auto-Sklong</code> is compatible with the following operating systems:</p> <ul> <li>MacOS \uf8ff (Careful, you may need to force your settings to be under intel x86_64 and not apple silicon if you hold an M-based chip)</li> <li>Linux \ud83d\udc27</li> <li>On Windows \ud83e\ude9f, you are recommended to run the library within a Docker container under a Linux distribution.</li> </ul> <p>Warning</p> <p>We haven't tested it on Windows without Docker.</p>"},{"location":"quick-start/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>To perform AutoML on your longitudinal analysis with <code>Auto-Sklong</code>, use the following two-easy-steps.</p> <ul> <li> <p>First, load and prepare  your dataset using the <code>LongitudinalDataset</code> class of  <code>Sklong</code>.</p> </li> <li> <p>Second, use the <code>GamaLongitudinalClassifier</code> class of <code>Auto-Sklong</code>.  Following instantiating it set up its <code>hyperparameters</code> or let default, you can apply the popular  fit, predict, prodict_proba, methods in the same way that <code>Scikit-learn</code>  does, as shown in the example below. It will then automatically search for the best model and hyperparameters for your dataset.</p> </li> </ul> <p>Refer to the documentation for more information on the <code>GamaLongitudinalClassifier</code> class.</p> <pre><code>from sklearn.metrics import classification_report\nfrom scikit_longitudinal.data_preparation import LongitudinalDataset\nfrom gama.GamaLongitudinalClassifier import GamaLongitudinalClassifier\n\n# Load your longitudinal dataset\ndataset = LongitudinalDataset('./stroke.csv')\ndataset.load_data_target_train_test_split(\n  target_column=\"class_stroke_wave_4\",\n)\n\n# Pre-set or manually set your temporal dependencies \ndataset.setup_features_group(input_data=\"elsa\")\n\n# Instantiate the AutoML system\nautoml = GamaLongitudinalClassifier(\n    features_group=dataset.features_group(),\n    non_longitudinal_features=dataset.non_longitudinal_features(),\n    feature_list_names=dataset.data.columns.tolist(),\n)\n\n# Run the AutoML system to find the best model and hyperparameters\nmodel.fit(dataset.X_train, dataset.y_train)\n\n# Predictions and prediction probabilities\nlabel_predictions = automl.predict(X_test)\nprobability_predictions = automl.predict_proba(X_test)\n\n# Classification report\nprint(classification_report(y_test, label_predictions))\n\n# Export a reproducible script of the champion model\nautoml.export_script() \n</code></pre> <ol> <li>Define the <code>features_group</code> manually or use a pre-set from the <code>LongitudinalDataset</code> class. If your dataset comes from the ELSA database or similar, you can use the pre-sets like <code>.setup_features_group('elsa')</code>. These pre-sets simplify the process of assigning temporal dependencies. Learn more here.</li> <li>Define the <code>non_longitudinal_features</code> manually or use a pre-set from the <code>LongitudinalDataset</code> class. For example, if using the ELSA database, setting up features using <code>.setup_features_group('elsa')</code> automatically determines the non-longitudinal features. See details here.</li> <li>Customise the <code>GamaLongitudinalClassifier</code> with various hyperparameters or use default settings. This flexibility allows you to tailor the search process to your specific longitudinal dataset. For a full list of configurable options, refer to the API documentation.</li> <li>Use the <code>export_script</code> method to generate a Python script of the best model found during the AutoML search. This script enables you to reproduce the champion model independently of the <code>Auto-Sklong</code> system. More information can be found in the API documentation.</li> </ol> <p>Wants to understand what's the <code>feature_groups</code>? How your temporal dependencies are set via <code>pre-set</code> or <code>manually</code>?</p> <p>To understand how to set your temporal dependencies, please refer to the <code>Temporal Dependency</code> tab of the documentation.</p> <p>Wants more control on <code>hyper-parameters</code>?</p> <p>To see the full API reference, please refer to the <code>API</code> tab.</p> <p>Wants more information on the Search Space <code>Auto-Sklong</code> comes with?</p> <p>To see the full Search Space, please refer to the <code>Search Space</code> tab.</p> <p>Wants more to grasp the idea?</p> <p>To see more examples, please refer to the <code>Examples</code> tab of the documentation.</p>"},{"location":"quick-start/#references","title":"\ud83d\udcda References","text":"<p>[1] Kelloway, E.K. and Francis, L., 2012. Longitudinal research and data analysis. In Research methods in occupational health psychology (pp. 374-394). Routledge.</p> <p>[2] Ribeiro, C. and Freitas, A.A., 2019. A mini-survey of supervised machine learning approaches for coping with ageing-related longitudinal datasets. In 3<sup>rd</sup> Workshop on AI for Aging, Rehabilitation and Independent Assisted Living (ARIAL), held as part of IJCAI-2019 (num. of pages: 5).</p>"},{"location":"search_space/","title":"\ud83d\udd78\ufe0f The Search Space","text":""},{"location":"search_space/#the-search-space_1","title":"\ud83d\udd78\ufe0f The Search Space","text":"<p>Read the full paper</p> <p>If you are missing some context when reading the quick start on our proposed search space below.</p> <p>We highly recommend that you start reading the paper (which currently is sent to a conference) to gain a better  understanding of the intrinsic of our proposed search space.</p> <p>The <code>Auto-Sklong</code> proposed <code>sequantial</code> search space consists of three steps for preparing a pipeline for a  longitudinal machine learning classification task. The search space is defined by the steps below:</p> <p>Sequential Search Space in Three Steps</p> <ol> <li>Data Preparation: The first step is to either <code>flatten</code> the data or retain its temporal identity for use in subsequent steps.<ul> <li>Data Transformation: A number of techniques use the dataset's temporal identity to <code>flatten</code> it,  allowing standard machine learning techniques to be applied. Certain are very basics, with some e.g waves  summarised via mean/median, or more complex techniques such as <code>Separate Waves</code>, which build a classifier for each  wave of the data before combining the results with either classic or more complex ensembling techniques.</li> <li>Algorithm Adaptation: The second type of potential data preparation is simply preserving the dataset's  temporal identity so that subsequent steps using adapted techniques to understand such temporality can benefit it.</li> </ul> </li> <li>Pre-Processing: The second step is to pre-process the data using feature selections from our first version of      the proposed search space. In theory, any type of preprocessing could be used. Feel free to add yours to <code>Sklong</code>.      However, here is where the important process begins. Based on the previous step's choice, the pipeline has a limited      number of options that only fit the previous step's choice. For example, if the previous step was to begin with      algorithm adaptation-based data preparation techniques, a brand-new or adapted-to-standard preprocessing technique      for longitudinal data would be chosen rather than standard preprocessing techniques, which do not deal with the      temporal identity of the dataset. Similarly, if data transformations were performed instead, an algorithm      adaptation-based pipeline would no longer possible. Instead, a standard machine learning technique would be chosen.</li> <li>Classifiers: The last step is to select the pipeline's final classifier. Similarly, the decision is based on      the previous two steps.</li> </ol> <p>Here is a figure that may be useful for visualising the search space. In the meantime, we strongly recommend that  the reader read the paper (which currently is sent to a conference) to gain a better understanding of the intrinsic  nature of our proposed search space.</p> <p></p>"},{"location":"search_space/#how-to-modify-the-current-search-space","title":"\ud83d\udee0\ufe0f How to modify the current Search Space?","text":"<p>First and foremost, <code>GAMA</code>, and similary <code>Auto-Sklong</code> support <code>ConfigSpace</code>. Which, in a nutshell, is a simple python package to manage configuration spaces for algorithm configuration and  hyperparameter optimization tasks. It includes various modules to translate between different text formats  for configuration space descriptions. Read further their documentation if you are not familiar with it.</p> <p>In the meantime, here is how it is done in <code>GAMA</code> / <code>Auto-Sklong</code>:</p>"},{"location":"search_space/#data-preparation-techniques","title":"Data Preparation Techniques","text":"<p>Navigate first through the <code>gama/configuration/longitudinal_classification_task/data_preparation.py</code> file.  Every step of the search space has a dedicated file. Within which, they follow the same convention to define techniques to add to the search space. For the <code>Data Preparation</code>, see as follow.</p> <p><code>self.data_preparation_setup_map</code> defines the list of techniques to be used in the search space. However, it is of form object-based key-value pair. This means that while defining the name of the technique, you also reference a function that will be called to form the hyper-parameters associated with this technique.</p> <p>Let's take an example. I want to add <code>Aggregation Functions Mean</code> to the search space. Such function simply aggregate waves together using the mean function. See its documentation in <code>Sklong</code>.</p> <pre><code>self.data_preparation_setup_map = {\n            \"AggrFuncMean\": self.setup_aggr_func_mean,\n            ... \n}\n\n...\n\ndef setup_aggr_func_median(self, data_preparation: csh.CategoricalHyperparameter):\n    pass\n</code></pre> <p>This way, <code>AggrFuncMean</code> been added to the search space and later will be used in the pipeline by its very name. Therefore this means that it should be available within either <code>Scikit-Learn</code> or <code>Sklong</code>.</p> <p>To see how to configure hyper-parameters, let's jump into adding a pre-processing technique instead, step-2 of the search space.</p>"},{"location":"search_space/#pre-processing-techniques","title":"Pre-Processing Techniques","text":"<p>Similarly, it follows the same convention. Navigate to <code>gama/configuration/longitudinal_classification_task/preprocessors.py</code> file.</p> <p><code>self.preprocessors_setup_map</code> defines the list of preprocessing techniques to be used in the search space. Let's add one feature selection technique with associated hyper-parameters.</p> <pre><code>self.preprocessors_setup_map = {\n            \"CorrelationBasedFeatureSelectionPerGroup\": self.setup_cfs_per_group,\n            ... \n}\n\ndef setup_cfs_per_group(self, preprocessors: csh.CategoricalHyperparameter):\n    version = csh.CategoricalHyperparameter(\n        name=\"version__CorrelationBasedFeatureSelectionPerGroup\",\n        choices=[1, 2],\n        default_value=1,\n    )\n    self._add_hyperparameters_and_equals_conditions(\n        locals(), \"CorrelationBasedFeatureSelectionPerGroup\"\n    )\n</code></pre> <p>This way, <code>CorrelationBasedFeatureSelectionPerGroup</code> been added to the search space and later will be used in the  pipeline by its very name. Along with the hyper-parameter's name <code>version</code> with as choices <code>[1, 2]</code> and a default value of <code>1</code>. Here is used what do we call a <code>CategoricalHyperparameter</code>. To define it to the <code>CorrelationBasedFeatureSelectionPerGroup</code> you certainly have noticed that <code>__</code> symbols are added followed by the name of the technique. This ensures that if multiple techniques have a hyper-parameter <code>version</code>, <code>ConfigSpace</code> could differentiate them.</p> <p>Therefore, to understand more about the type of hyper-parameters you can define, please refer to the <code>ConfigSpace</code> documentation.</p> <p>Lastly, the name put to the technique should be available within either <code>Scikit-Learn</code> or <code>Sklong</code>.</p> <p>Lastly, let's jump into the last step of the search space, the classifiers.</p>"},{"location":"search_space/#classifiers","title":"Classifiers","text":"<p>Similarly, we repeat the process, navigate to <code>gama/configuration/longitudinal_classification_task/classifiers.py</code> file.</p> <p><code>self.classifiers_setup_map</code> defines the list of classifiers to be used in the search space. Let's add a standard <code>DecisionTree</code>.</p> <pre><code>self.classifiers_setup_map = {\n            \"DecisionTree\": self.setup_decision_tree,\n            ... \n}\n\n@property\n    def shared_hyperparameters(self):\n        return {\n            \"criterion\": [\"gini\", \"entropy\"],\n            \"min_samples_split\": {\"lower\": 2, \"upper\": 20, \"default_value\": 2},\n            \"min_samples_leaf\": {\"lower\": 1, \"upper\": 20, \"default_value\": 1},\n            \"max_depth\": {\"lower\": 2, \"upper\": 10, \"default_value\": 2},\n        }\n\ndef setup_decision_tree(self, classifiers: csh.CategoricalHyperparameter):\n    criterion = csh.CategoricalHyperparameter(\n        \"criterion__DecisionTreeClassifier\",\n        self.shared_hyperparameters[\"criterion\"],\n    )\n    min_samples_split = csh.UniformIntegerHyperparameter(\n        \"min_samples_split__DecisionTreeClassifier\",\n        **self.shared_hyperparameters[\"min_samples_split\"],\n    )\n    min_samples_leaf = csh.UniformIntegerHyperparameter(\n        \"min_samples_leaf__DecisionTreeClassifier\",\n        **self.shared_hyperparameters[\"min_samples_leaf\"],\n    )\n    max_depth = csh.UniformIntegerHyperparameter(\n        \"max_depth__DecisionTreeClassifier\",\n        **self.shared_hyperparameters[\"max_depth\"],\n    )\n    self._add_hyperparameters_and_equals_conditions(\n        locals(), \"DecisionTreeClassifier\"\n    )\n</code></pre> <p>This way, <code>DecisionTree</code> been added to the search space and later will be used in the pipeline by its very name. Along with the hyper-parameters <code>criterion</code>, <code>min_samples_split</code>, <code>min_samples_leaf</code>, and <code>max_depth</code>. Each with their own default values and ranges. However, here you could notice a <code>shared_hyperparameters</code> property. This is to ensure that if multiple classifiers have  the same hyper-parameters, we could re-use them. This is a good practice to avoid redundancy.</p> <p>Therefore, to understand more about the type of hyper-parameters you can define, please refer to the <code>ConfigSpace</code> documentation.</p> <p>Lastly, the name put to the technique should be available within either <code>Scikit-Learn</code> or <code>Sklong</code>.</p> <p>To deep dive more into the search space</p> <p>For instance, if you have dynamic hyper-parameters such as <code>max_features</code> in some trees ensemble, or  would like to understand how the constraint between steps works in practice.</p> <p>We recommend that you start reading the paper (which currently is sent to a conference) to gain a better understanding of the intrinsic, and then navigate to <code>gama/configuration/longitudinal_classification.py</code> file.</p>"},{"location":"API/","title":"API Reference","text":"<p>Welcome to the full API documentation of the <code>Auto-Sklong</code> AutoML toolbox. </p> <p>Be aware!</p> <p>Considering <code>Auto-Sklong</code> is based on <code>GAMA</code>.  We frequently redirect users to the official <code>GAMA</code> documentation. In addition to the extensive  <code>Sklong</code> official documentation. Therefore, be aware that the following documentation will be more brief due to the extensive documentation of  <code>GAMA</code> and  <code>Sklong</code>.</p> <p>As a result, by relying on those two, we greatly improves maintainability and consistency. However, visually speaking, you will need to switch between documents. As our contributor base grows,  we may consider including the full <code>GAMA</code> documentation as a subset to reduce back and forth.</p> <p>Nonetheless, <code>Sklong</code> will remains a separate documentation as it is a different project. No <code>AutoML</code> related, but a <code>Longitudinal</code> machine learning library toolbox.</p>"},{"location":"API/#automl-classes","title":"AutoML Classes","text":"<ul> <li>Gama Longitudinal Classifier</li> <li>Gama Base (redirect to GAMA)</li> </ul>"},{"location":"API/#search-methods","title":"Search Methods","text":"<ul> <li>Bayesian optimisation (BO)</li> <li>Asynchronous Evolutionary Algorithm (Async EA) (redirect to GAMA)</li> <li>Asynchronous Successive Halving (ASHA) (redirect to GAMA)</li> <li>Random Search (redirect to GAMA)</li> </ul> <p>Were you looking to update/look-into the <code>Auto-Skong</code>'s search space?</p> <p>We got you covered! Check out the <code>search space</code> page.</p>"},{"location":"API/Gama_Longitudinal_Classifier/","title":"Gama Longitudinal Classifier","text":""},{"location":"API/Gama_Longitudinal_Classifier/#gamalongitudinalclassifier","title":"GamaLongitudinalClassifier","text":"<p>source</p> <p><pre><code>GamaLongitudinalClassifier(\n   features_group: List[List[Union[int, str]]],\n   non_longitudinal_features: List[Union[int, str]],\n   feature_list_names: List[str], update_feature_groups_callback: Union[Callable, str] = 'default',\n   search_space: Optional[cs.ConfigurationSpace] = None, scoring: Metric = 'roc_auc',\n   max_pipeline_length: Optional[int] = None, search: Optional[BaseSearch] = None,\n   *args, **kwargs\n)\n</code></pre> The <code>GamaLongitudinalClassifier</code> is the principal class for running <code>Auto-Sklong</code>, specifically designed to  handle longitudinal datasets. It integrates the proposed <code>search space</code> and employs various search methods to effectively  explore the longitudinal-based <code>search space</code> for your dataset.</p> <p>Naming Convention: <code>GamaLongitudinalClassifier</code></p> <p>The name <code>GamaLongitudinalClassifier</code> reflects its foundation on the <code>GAMA</code> framework, ensuring consistency with  the framework's naming conventions, even though it is a specialised fork tailored for longitudinal data.</p> <p>Understanding <code>features_group</code> and <code>non_longitudinal_features</code></p> <p>To leverage the full potential of <code>GamaLongitudinalClassifier</code>, it is crucial to understand the mandatory parameters  <code>features_group</code> and <code>non_longitudinal_features</code>. These parameters enable the classifiers' abilities to manage the temporal dependencies in your dataset. Detailed information can be found in the Temporal Dependencies documentation page</p> <p>Refer to <code>GAMA base</code> Documentation</p> <p>The <code>GamaLongitudinalClassifier</code> inherits many parameters from the <code>GAMA</code> base class (e.g the max total time the AutoML search goes on). A core class in the <code>GAMA</code> AutoML framework to all sub-class such as the standard <code>GamaClassifier</code> or <code>GamaRegressor</code> classes. For comprehensive details on these inherited parameters, consult the GAMA Base API documentation</p>"},{"location":"API/Gama_Longitudinal_Classifier/#parameters","title":"Parameters","text":"<ul> <li>features_group (<code>List[List[Union[int, str]]]</code>): A temporal matrix representing the temporal dependency of a longitudinal dataset. Each tuple/list of integers in the outer list represents the indices of a longitudinal attribute's waves, with each longitudinal attribute having its own sublist in that outer list. For more details, see the documentation's <code>Temporal Dependency</code> page.</li> <li>non_longitudinal_features (<code>List[Union[int, str]]</code>): A list of indices or names of features that are not longitudinal.</li> <li>feature_list_names (<code>List[str]</code>): A list of feature names in the dataset.</li> <li>update_feature_groups_callback (<code>Union[Callable, str]</code>, optional): Callback function to update feature groups. This function is invoked to update the structure of longitudinal features during pipeline transformations. By default, if you did not change the <code>search space</code>, you should be all right not to set it it up. Read further in the <code>Sklong</code> documentation here</li> <li>search_space (<code>Optional[cs.ConfigurationSpace]</code>): The <code>search space</code> being explored by the system. The original is by default, another one could be passed. Further explore the <code>Search_Space</code> documentation page.</li> <li>scoring (<code>Metric</code>, default='roc_auc'): The metric used for evaluating the performance of the model. Similar to <code>Scikit-Learn</code> / <code>Auto-Sklearn</code>, you can pass a custom <code>Metric</code> scoring function that the AutoML system will have to optimise.</li> <li>max_pipeline_length (<code>Optional[int]</code>, default=None): The maximum length of the pipeline to be searched. Whether you would like to have a <code>pre-processing</code> technique in the middle or not. If you put <code>2</code>, it will discard the <code>pre-processing</code> step of the <code>search space</code>.</li> <li>search (<code>Optional[BaseSearch]</code>, default=None): The search strategy used for pipeline optimization. Either, <code>BayesianOptimization</code>, <code>RandomSearch</code>, <code>Asynchronous Evolutionary Algorithm</code>, or <code>Asynchronous Successive Halving</code>. Further explore the Search Methods documentation section.</li> <li>args: Additional arguments.</li> <li>kwargs: Additional keyword arguments.</li> </ul> <p>More are available, here in the GAMA base documentation. Such as, the <code>max_total_time</code>, <code>max_eval_time</code>, etc.</p>"},{"location":"API/Gama_Longitudinal_Classifier/#attributes","title":"Attributes","text":"<ul> <li>classes_ (<code>ndarray</code> of shape (n_classes,)): The class labels.</li> <li>n_classes_ (<code>int</code>): The number of classes.</li> <li>feature_importances_ (<code>ndarray</code> of shape (n_features,)): The feature importances.</li> <li>best_pipeline_ (<code>Pipeline</code> object): The best pipeline found during the search.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#methods","title":"Methods","text":""},{"location":"API/Gama_Longitudinal_Classifier/#fit","title":"Fit","text":"<p>source</p> <pre><code>.fit(\n   x: Union[pd.DataFrame, np.ndarray], y: Union[pd.Series, np.ndarray],\n   *args, **kwargs\n)\n</code></pre> <p>Fit the <code>Gama Longitudinal Classifier</code>. Or in another word, start the AutoML experiment on your input data. This takes the amount of time you set in the <code>max_total_time</code> parameter of the GAMA Base class.</p>"},{"location":"API/Gama_Longitudinal_Classifier/#parameters_1","title":"Parameters","text":"<ul> <li>x (<code>Union[pd.DataFrame, np.ndarray]</code>): The training input samples of shape <code>(n_samples, n_features)</code>.</li> <li>y (<code>Union[pd.Series, np.ndarray]</code>): The target values of shape <code>(n_samples,)</code>.</li> <li>args: Additional arguments.</li> <li>kwargs: Additional keyword arguments.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#returns","title":"Returns","text":"<ul> <li>GamaLongitudinalClassifier: The fitted AutoML classifier. Capable of predicting the target for input X using the best found pipeline.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#predict","title":"Predict","text":"<p>source</p> <pre><code>.predict(\n   x: Union[pd.DataFrame, np.ndarray]\n)\n</code></pre> <p>Predict the target for input X using the best found pipeline.</p> <p>This method computes the class labels for the input samples.</p>"},{"location":"API/Gama_Longitudinal_Classifier/#parameters_2","title":"Parameters","text":"<ul> <li>x (<code>Union[pd.DataFrame, np.ndarray]</code>): The input samples of shape <code>(n_samples, n_features)</code>.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#returns_1","title":"Returns","text":"<ul> <li>np.ndarray: The predicted class labels of shape <code>(n_samples,)</code>.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#predict-proba","title":"Predict Proba","text":"<p>source</p> <pre><code>.predict_proba(\n   x: Union[pd.DataFrame, np.ndarray]\n)\n</code></pre> <p>Predict class probabilities for X using the best found pipeline.</p> <p>This method computes the class probabilities for the input samples.</p>"},{"location":"API/Gama_Longitudinal_Classifier/#parameters_3","title":"Parameters","text":"<ul> <li>x (<code>Union[pd.DataFrame, np.ndarray]</code>): The input samples of shape <code>(n_samples, n_features)</code>.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#returns_2","title":"Returns","text":"<ul> <li>np.ndarray: The predicted class probabilities of shape <code>(n_samples, n_classes)</code>.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#predict-proba-from-file","title":"Predict Proba from File","text":"<p>source</p> <pre><code>.predict_proba_from_file(\n   arff_file_path: str, target_column: Optional[str] = None,\n   encoding: Optional[str] = None\n)\n</code></pre> <p>Predict class probabilities from an ARFF file.</p> <p>This method computes the class probabilities for the input samples in the ARFF file.</p>"},{"location":"API/Gama_Longitudinal_Classifier/#parameters_4","title":"Parameters","text":"<ul> <li>arff_file_path (<code>str</code>): The path to the ARFF file containing the input samples.</li> <li>target_column (<code>Optional[str]</code>, default=None): The name of the target column in the ARFF file. If None, the last column is assumed to be the target.</li> <li>encoding (<code>Optional[str]</code>, default=None): The encoding of the ARFF file.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#returns_3","title":"Returns","text":"<ul> <li>np.ndarray: The predicted class probabilities of shape <code>(n_samples, n_classes)</code>.</li> </ul>"},{"location":"API/Gama_Longitudinal_Classifier/#examples","title":"Examples","text":"<p>Make sure to open the little <code>+</code> icon next to any line having them</p> <p>The examples below are just a starting point. Make sure to open the little <code>+</code> icon next to any line having them to see further explanation / guidance.</p>"},{"location":"API/Gama_Longitudinal_Classifier/#dummy-longitudinal-dataset","title":"Dummy Longitudinal Dataset","text":"<p>Consider the following dataset: <code>stroke.csv</code></p> <p>Features:</p> <ul> <li><code>smoke</code> (longitudinal) with two waves/time-points</li> <li><code>cholesterol</code> (longitudinal) with two waves/time-points</li> <li><code>age</code> (non-longitudinal)</li> <li><code>gender</code> (non-longitudinal)</li> </ul> <p>Target:</p> <ul> <li><code>stroke</code> (binary classification) at wave/time-point 2 only for the sake of the example</li> </ul> <p>The dataset is shown below:</p> smoke_w1 smoke_w2 cholesterol_w1 cholesterol_w2 age gender stroke_w2 0 1 0 1 45 1 0 1 1 1 1 50 0 1 0 0 0 0 55 1 0 1 1 1 1 60 0 1 0 1 0 1 65 1 0"},{"location":"API/Gama_Longitudinal_Classifier/#example-1-basic-usage","title":"Example 1: Basic Usage","text":"<pre><code>from sklearn.metrics import classification_report\nfrom scikit_longitudinal.data_preparation import LongitudinalDataset\nfrom gama.GamaLongitudinalClassifier import GamaLongitudinalClassifier\n\n# Load your longitudinal dataset\ndataset = LongitudinalDataset('./stroke.csv') # (1)\ndataset.load_data_target_train_test_split(\n  target_column=\"stroke_w2\",\n)\n\n# Pre-set or manually set your temporal dependencies \ndataset.setup_features_group(input_data=\"elsa\") # (2)\n\n# Instantiate the AutoML system\nautoml = GamaLongitudinalClassifier( # (3)\n    features_group=dataset.features_group(),\n    non_longitudinal_features=dataset.non_longitudinal_features(), # (4)\n    feature_list_names=dataset.data.columns,\n)\n\n# Run the AutoML system to find the best model and hyperparameters\nautoml.fit(dataset.X_train, dataset.y_train)\n\n# Predictions and prediction probabilities\nlabel_predictions = automl.predict(X_test)\nprobability_predictions = automl.predict_proba(X_test)\n\n# Classification report\nprint(classification_report(y_test, label_predictions))\n</code></pre> <ol> <li>To further explore the documentation about <code>LongitudinalDataset</code> available via <code>Sklong</code>, read here.</li> <li>Define the features_group manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>.</li> <li>Instantiate the <code>GamaLongitudinalClassifier</code> class with the features_group and non-longitudinal features and the rest by default.</li> <li>Define the non-longitudinal features manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>, then the non-longitudinal features would have been automatically set.</li> </ol>"},{"location":"API/Gama_Longitudinal_Classifier/#example-2-how-to-set-my-own-scoring-function","title":"Example 2: How to set my own scoring function","text":"<pre><code>from sklearn.metrics import f1_score\nfrom scikit_longitudinal.data_preparation import LongitudinalDataset\nfrom gama.GamaLongitudinalClassifier import GamaLongitudinalClassifier\n\n\n# Load your longitudinal dataset\ndataset = LongitudinalDataset('./stroke.csv') # (1)\ndataset.load_data_target_train_test_split(\n  target_column=\"stroke_w2\",\n)\n\n# Pre-set or manually set your temporal dependencies \ndataset.setup_features_group(input_data=\"elsa\") # (2)\n\n# Instantiate the AutoML system\nautoml = GamaLongitudinalClassifier( # (3)\n    features_group=dataset.features_group(),\n    non_longitudinal_features=dataset.non_longitudinal_features(), # (4)\n    feature_list_names=dataset.data.columns,\n    scoring=f1_score # (5)\n)\n\n# Run the AutoML system to find the best model and hyperparameters\nautoml.fit(dataset.X_train, dataset.y_train)\n\n# Predictions and prediction probabilities\nlabel_predictions = automl.predict(X_test)\nprobability_predictions = automl.predict_proba(X_test)\n\n# Classification report\nprint(classification_report(y_test, label_predictions))\n</code></pre> <ol> <li>To further explore the documentation about <code>LongitudinalDataset</code> available via <code>Sklong</code>, read here.</li> <li>Define the features_group manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>.</li> <li>Instantiate the <code>GamaLongitudinalClassifier</code> class with the features_group and non-longitudinal features and the rest by default.</li> <li>Define the non-longitudinal features manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>, then the non-longitudinal features would have been automatically set.</li> <li>Set the scoring function to <code>f1_score</code> instead of the default <code>roc_auc</code>. You could create your own scorer with <code>make_scorer</code> from <code>sklearn.metrics</code> if you want to use a custom metric. See furthere here.</li> </ol>"},{"location":"API/Gama_Longitudinal_Classifier/#example-3-how-to-export-the-best-pipeline","title":"Example 3: How to export the best pipeline","text":"<pre><code>from sklearn.metrics import classification_report\nfrom scikit_longitudinal.data_preparation import LongitudinalDataset\nfrom gama.GamaLongitudinalClassifier import GamaLongitudinalClassifier\n\n# Load your longitudinal dataset\ndataset = LongitudinalDataset('./stroke.csv') # (1)\ndataset.load_data_target_train_test_split(\n  target_column=\"stroke_w2\",\n)\n\n# Pre-set or manually set your temporal dependencies \ndataset.setup_features_group(input_data=\"elsa\") # (2)\n\n# Instantiate the AutoML system\nautoml = GamaLongitudinalClassifier( # (3)\n    features_group=dataset.features_group(),\n    non_longitudinal_features=dataset.non_longitudinal_features(), # (4)\n    feature_list_names=dataset.data.columns,\n)\n\n# Run the AutoML system to find the best model and hyperparameters\nautoml.fit(dataset.X_train, dataset.y_train)\n\n# Export the best pipeline\nautoml.export_script('my_pipeline_script.py') # (5)\n</code></pre> <ol> <li>To further explore the documentation about <code>LongitudinalDataset</code> available via <code>Sklong</code>, read here.</li> <li>Define the features_group manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>.</li> <li>Instantiate the <code>GamaLongitudinalClassifier</code> class with the features_group and non-longitudinal features and the rest by default.</li> <li>Define the non-longitudinal features manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>, then the non-longitudinal features would have been automatically set.</li> <li>Export the best pipeline to a Python file named <code>my_pipeline_script.py</code>. The resulting script will define a variable <code>pipeline</code> or <code>ensemble</code>, depending on the post-processing method that was used after search. Reader further about the post-ensembling methods in the <code>GAMA</code> class documentation.</li> </ol>"},{"location":"API/Gama_Longitudinal_Classifier/#example-4-how-to-play-with-the-gama-base-parameters","title":"Example 4: How to play with the <code>GAMA</code> base parameters","text":"<pre><code>from sklearn.metrics import classification_report\nfrom scikit_longitudinal.data_preparation import LongitudinalDataset\nfrom gama.GamaLongitudinalClassifier import GamaLongitudinalClassifier\nfrom gama.search_methods import RandomSearch\n\n# Load your longitudinal dataset\ndataset = LongitudinalDataset('./stroke.csv') # (1)\ndataset.load_data_target_train_test_split(\n  target_column=\"stroke_w2\",\n)\n\n# Pre-set or manually set your temporal dependencies \ndataset.setup_features_group(input_data=\"elsa\") # (2)\n\n# Instantiate the AutoML system\nautoml = GamaLongitudinalClassifier( # (3)\n    features_group=dataset.features_group(),\n    non_longitudinal_features=dataset.non_longitudinal_features(), # (4)\n    feature_list_names=dataset.data.columns,\n    max_total_time=86400, # (5)\n    max_eval_time=1000, # (6)\n    n_jobs=4, # (7)\n    max_memory_mb=2000, # (8)\n    post_processing=EnsemblePostProcessing(), # (9)\n    output_directory=\"my_output\", # (10)\n    store=\"all\", # (11)\n    search=RandomSearch(), # (12)\n)\n\n# Run the AutoML system to find the best model and hyperparameters\nautoml.fit(dataset.X_train, dataset.y_train)\n\n# Predictions and prediction probabilities\nlabel_predictions = automl.predict(X_test)\nprobability_predictions = automl.predict_proba(X_test)\n\n# Classification report\nprint(classification_report(y_test, label_predictions))\n</code></pre> <ol> <li>To further explore the documentation about <code>LongitudinalDataset</code> available via <code>Sklong</code>, read here.</li> <li>Define the features_group manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>.</li> <li>Instantiate the <code>GamaLongitudinalClassifier</code> class with the features_group and non-longitudinal features and the rest by default.</li> <li>Define the non-longitudinal features manually or use a pre-set from the <code>LongitudinalDataset</code> class. If the data was from the ELSA database, you could use as per the example the pre-sets such as <code>.setup_features_group('elsa')</code>, then the non-longitudinal features would have been automatically set.</li> <li>Set the maximum total time \u2013 in seconds \u2013 for the AutoML system to 24 hours (86400 seconds). Read further in the <code>Gama base</code> class documentation.</li> <li>Set the maximum evaluation time \u2013 in seconds \u2013 for each pipeline evaluation to 1000 seconds. Read further in the <code>Gama base</code> class documentation.</li> <li>Turn on the parallel processing with 4 jobs. This means that 4 candidates at the same time will be able to be evaluated, if the number of CPUs availale permits-so. Read further in the <code>Gama base</code> class documentation.</li> <li>Set the maximum memory usage \u2013 in megabytes \u2013 for the AutoML system to 2000 MB. This means that above the current candidate's evaluation will crash. Read further in the <code>Gama base</code> class documentation.</li> <li>Set the post-processing method to <code>EnsemblePostProcessing</code>. This will ensemble the best pipelines found during the search. Read further in the official <code>GAMA</code> documentation here.</li> <li>Set the output directory to <code>my_output</code>. This will save the results of the search in the <code>my_output</code> directory. Read further in the <code>Gama base</code> class documentation.</li> <li>Set the store level to <code>all</code>, which keep logs and cache with models and predictions. Read further in the <code>Gama base</code> class documentation.</li> <li>Run the AutoML's search under <code>RandomSearch</code> strategy. Others are available, read further in the Search Methods section.</li> </ol>"},{"location":"API/search_methods/bayesian_optimisation/","title":"Bayesian Optimisation","text":""},{"location":"API/search_methods/bayesian_optimisation/#bayesianoptimisation","title":"BayesianOptimisation","text":"<p>source</p> <pre><code>BayesianOptimisation(\n    scenario_params: Optional[dict] = None,\n    initial_design_params: Optional[dict] = None, \n    facade_params: Optional[dict] = None,\n    config_to_individual_fun: Callable = config_to_individual, \n    **kwargs\n)\n</code></pre> <p>Bayesian Optimisation is an advanced technique for hyperparameter tuning and pipeline optimisation.  It efficiently searches through the hyperparameter space to find the best model configurations by using a  probabilistic model to guide the search. The Bayesian Optimisation framework being leveraged via <code>GAMA</code> and <code>Auto-Sklong</code>, is <code>SMAC3</code> (Sequential Model-based Algorithm Configuration), which is a state-of-the-art implementation of Bayesian Optimisation. Available at <code>SMAC3</code>.</p> <p>Next is what parameters can be passed to the <code>BayesianOptimisation</code> when being  instantiated in the <code>GamaLongitudinalClassifier</code>'s <code>search</code> parameter.</p>"},{"location":"API/search_methods/bayesian_optimisation/#parameters","title":"Parameters","text":"<ul> <li>scenario_params (<code>Optional[dict]</code>): The Scenario is used to provide environment variables. For example, if you want to limit the optimization process by a time limit or want to specify where to save the results. By default is provided the <code>seed</code> and the <code>output_directory</code> of the <code>GAMA base</code> class. Therefore, this is an optional parameter. To modify at your own risk.</li> <li>initial_design_params (<code>Optional[dict]</code>): Parameters for the initial design, which dictates how the initial set of configurations is generated. By default, the initial design is random. This is an optional parameter, to modify at your own risk. How to set it up and with what can be found in the following Python script.</li> <li>facade_params (<code>Optional[dict]</code>): Parameters for the SMAC facade, which manages the overall optimization process. Similar to <code>initial_design_params</code>, this is an optional parameter, to modify at your own risk. How to set it up and with what can be found in the following Python script.</li> <li>config_to_individual_fun (<code>Callable</code>): Function that converts a configuration into an individual pipeline. By default, no need to modify it. However, if you introduce a brand-new <code>search space</code>, you might need to modify it. Explore the code and open a new issue if you need help.</li> <li>kwargs: Additional parameters for custom configurations.</li> </ul> <p>SMAC3 is being used, look their documentation for more information</p> <p>The <code>SMAC3</code> documentation can be found here.  It is recommended to check it out to understand the full potential of the Bayesian Optimisation framework being  used in <code>Auto-Sklong</code>. We simply implemented a wrapper around it to make it easier to use in <code>GAMA</code>.</p>"},{"location":"examples/","title":"Coming Soon!","text":""},{"location":"examples/#coming-soon_1","title":"Coming Soon!","text":"<p>We're currently working on creating a comprehensive examples page for you.  This page will feature <code>Jupyter notebooks</code> that demonstrate how to use <code>Auto-Sklong</code> effectively. </p> <p>Note</p> <p>In the meantime, throughout the API reference, you can find examples of how to use each class and method presented.</p> <p>Stay tuned for updates! We're excited to share these resources with you soon. </p>"}]}